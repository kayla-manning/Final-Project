---
output: html_document
---

## Linear Regression of Interhouse Swipes with Month, Year, and House

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# calling libraries I need as I go

library(tidyverse)
library(broom)
library(gt)

# loading data

tidy_int_reg_bag <- read_csv("all_tidy.csv",
                             col_types = cols(col_date(format = ''),
                                             col_character(),
                                             col_character(),
                                             col_character(),
                                             col_character(),
                                             col_character(),
                                             col_double()))
anim_data <- read_csv("anim_data.csv")

```

Curious about the relationship between distance from Harvard Yard and interhouse swipe counts, I plotted the median number of interhouse swipes for each house in each academic year as a function of the distance from the John Harvard Statue. I chose John Harvard as a central location on campus because it sits relatively equidistant from Sever and the Science Center, two of the most popular classroom buildings on campus. I hypothesized that a greater distance would be associated with fewer interhouse swipes, and the below plot confirms that notion.

```{r plot_int_distance}

# first I will run a simple regression with just distance and the average
# monthly interhouse swipes for each house. for both plots, the raw data appears
# to follow the same general shape, just with more interhouse swipes in the
# 2018-2019 academic year compared to the previous.

anim_data %>% 
  group_by(house, year, distance) %>% 
  summarise(avg_int = mean(avg_int)) %>% 
  ungroup() %>% 
  mutate(year = as_factor(year)) %>% 
  ggplot(aes(distance, avg_int, color = year)) +
  geom_point() +
  geom_jitter() +
  facet_wrap(~ year) +
  labs(title = "Average Interhouse Swipes Per Meal by Distance",
       subtitle = "Distance is measured in feet from the John Harvard Statue",
       caption = "Note that all FlyBy swipes are interhouse") +
  xlab("Distance (ft) from the John Harvard Statue") +
  ylab("Average Interhouse Swipes Per Dining Location")

```

You can see that between the two academic years, the houses closest to the John Harvard Statue experienced a surge in the number of interhouse swipes relative to the previous academic year. This likely occurred as a result of increased time pressure due to the schedule change. 

Another point worth noting is that FlyBy is a huge outlier on this plot. Because FlyBy is not a house, all student swipes are counted as interhouse. For that reason, I will exclude FlyBy from my regression.

We see that distance and year appear to have an association with average number of interhouse swipes. I will run a regression to estimate the average treatment effect of house and month on the average number of interhouse swipes.

```{r fix_plot}

# I will remove FlyBy from the data since all swipes are considered interhouse
# swipes; now that I have a look at the data, I will try to run a regression in
# the next chunk. It appears that a cubic function might be the best fit, but I
# will try other models and compare R^2 values.

anim_data %>% 
  filter(house != "FlyBy") %>% 
  group_by(house, year, distance) %>% 
  summarise(avg_int = mean(avg_int)) %>% 
  ungroup() %>% 
  mutate(year = as_factor(year)) %>% 
  ggplot(aes(distance, avg_int, color = year)) +
  geom_point() +
  geom_jitter() +
  facet_wrap(~ year) +
  labs(title = "Average Interhouse Swipes Per Meal by Distance",
       subtitle = "Distance is measured in feet from the John Harvard Statue",
       caption = "Only looking at upperclassman houses") +
  xlab("Distance (ft) from the John Harvard Statue") +
  ylab("Average Interhouse Swipes Per Dining Location") +
  geom_smooth(method = "lm", se = FALSE, formula = y ~ x)

```

I began my investigation to best explain the variables behind interhouse swipe counts by building multiple linear models and assessing the efficacy of each. For example, the above plot is of a linear regression of average interhouse swipes on distance; this model only accounts for about 44% of the variation in the data. I found that a model looking at each house and controlling for the month and academic year best explains the variation in interhouse swipe counts. My linear model explains just over 79% of variation present in the data. Considering that this data does not provide any variables to quantify social connectivity between houses, such as students dining with friends in other houses, 79% explanation captures our data very well.

The below graph displays the estimated interhouse swipe counts per meal at each house, controlling for month and academic year. Each point represents the average count of interhouse swipes at each meal for that respective house, while the error bars represent the lower and upper bounds of our 95% confidence intervals. We are 95% confident that the true average number of interhouse swipes for each month is captured within our error bars.

When the error bars between houses do not overlap along the x-axis, that means that the difference in the average number of interhouse swipe counts per meal is statistically significant. That is, we are 95% confident that the true number of interhouse swipe counts per meal is different between the houses when controlling for month. For example, Lowell, Quincy, Adams, and Winthrop do not overlap with any of the remaining 8 houses. They have a significantly greater number of interhouse swipes per meal compared to the other houses when controlling for month.


```{r model}

# I am removing FlyBy from the data because it will throw off the regression
# estimates.

new_anim_data  <- anim_data %>% 
  filter(house != "FlyBy") %>% 
  mutate(month_year = as_factor(month_year))


# testing the strength of our model with just distance; only 0.4422738 of
# variation is accounted for... let's see if we can do better

simple_r2 <- new_anim_data %>% 
  lm(avg_int ~ distance, data = .) %>% 
  glance() %>% 
  pull(adj.r.squared)

# after testing out many multiple regressions, this is the best adj.r.squared
# that I could get. 0.7934766 of variation is accounted for with this model.
# pretty good!

mult <- new_anim_data %>% 
  lm(avg_int ~ house + month_year, data = .)

mult_r2 <- mult %>% 
  glance() %>% 
  pull(adj.r.squared)

```

```{r reg_house_graph}

# taking info from gt table and putting it into a graph

mult %>% 
  tidy(conf.int = TRUE) %>% 
  slice(1:12) %>% 
  mutate(estimate = ifelse(term != "(Intercept)", 
                           estimate + 97.07523148, estimate),
         conf.low = ifelse(term != "(Intercept)",
                           conf.low + 97.07523148, conf.low),
         conf.high = ifelse(term != "(Intercept)",
                            conf.high + 97.07523148, conf.high),
         term = ifelse(term == "(Intercept)", "Adams",
                       str_remove(term, "house")),
         term = term %>% 
                 as_factor() %>% 
                 fct_reorder(estimate)) %>% 
  ggplot(aes(term, estimate, color = term)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  coord_flip() +
  xlab("House") +
  ylab("Estimated Interhouse Swipes Per Meal") +
  labs(title = "Estimated Interhouse Swipes Per Meal for Each House",
       subtitle = "Month and year are included as fixed effects in this model",
       color = "House") 

```

While the above plot shows the average interhouse swipe counts for each house while controlling for month, the below plot displays the estimated interhouse swipe counts per meal associated with each month while controlling for house.

As we can see, all months have some overlap between the error bars, so there is not a statistically significant difference between the interhouse swipe counts and any two months. However, we can see that January of 2019, on average, experience the greatest number of interhouse swipe counts while December of 2017 saw the least.

```{r reg_month_graph}

# basically taking the info from the gt table but plotting it with month instead
# of house

mult %>% 
  tidy(conf.int = TRUE) %>% 
  slice(-(2:12)) %>% 
  mutate(estimate = ifelse(term != "(Intercept)", 
                           estimate + 97.07523148, estimate),
         conf.low = ifelse(term != "(Intercept)",
                           conf.low + 97.07523148, conf.low),
         conf.high = ifelse(term != "(Intercept)",
                            conf.high + 97.07523148, conf.high),
         term = ifelse(term == "(Intercept)", "1/2018",
                       str_remove(term, "month_year")),
         term = term %>% 
                 as_factor() %>% 
                 fct_reorder(estimate)) %>% 
  ggplot(aes(term, estimate, color = term)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  coord_flip() +
  xlab("Month and Year") +
  ylab("Estimated Interhouse Swipes Per Meal") +
  labs(title = "Estimated Interhouse Swipes Per Meal for Each Month",
       subtitle = "Houses are included as fixed effects in this model",
       color = "Month") 
  


```

